{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/img/teclab_logo.png\" alt=\"Teclab logo\" width=\"170\">\n",
    "\n",
    "**Author**: Hector Vergara ([LinkedIn](https://www.linkedin.com/in/hector-vergara/))\n",
    "\n",
    "**Repository**: [nlp_apis](https://github.com/hhvergara/nlp_apis)\n",
    "\n",
    "**Python Notebook**: [API3.ipynb](https://github.com/hhvergara/nlp_apis/blob/main/API3.ipynb)\n",
    "\n",
    "----\n",
    "\n",
    "# API 3:\n",
    "\n",
    "### Contexto\n",
    "\n",
    "Al día siguiente, presentamos los resultados anteriores al equipo y obtenemos el VoBo para continuar. Efectivamente, lo obtenido hasta el momento hace sentido, y lo importante es que ya se cuenta con un corpus de comentarios limpio y se tiene un vocabulario resumido.\n",
    "\n",
    "Alguien del equipo expresa que ya se puede aplicar, entonces, un modelo para clasificación, por lo que -con todo la razón- argumentamos que primero se debe obtener una representación vectorial del corpus, y justamente es lo que se pondrá en foco a continuación.\n",
    "\n",
    "### Consignas\n",
    "\n",
    "Representación vectorial: en esta parte, se debe aplicar un modelo de representación vectorial. Se recomienda el uso de TfidfVectorizer por sobre una representación BoW debido a que facilita la inclusión de los emojis, tal como se expone en el siguiente ejemplo:\n",
    "\n",
    "![example 1](./assets/img/API3_1.png)\n",
    "\n",
    "El modelo para la vectorización debe ajustarse primero con los datos X de entrenamiento y, posteriormente, realizar la transformación con los datos X de testeo:\n",
    "\n",
    "![example 2](./assets/img/API3_2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vinyl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vinyl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vinyl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\vinyl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\vinyl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vinyl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Library Imports\n",
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from  nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "__version__ = '0.0.1'\n",
    "__email__ = 'hhvservice@gmail.com'\n",
    "__author__ = 'Hector Vergara'\n",
    "__annotations__ = 'https://www.linkedin.com/in/hector-vergara/'\n",
    "__base_dir__ = Path().absolute()\n",
    "__data_dir__ = os.path.join(__base_dir__, 'data')\n",
    "filename_data = os.path.join(__data_dir__, 'sentiment_analysis_dataset.csv')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargamos el dataset \"sentiment-analysis-dataset\" de kaggle para realizar las pruebas.\n",
    "\n",
    "Referencia: https://www.kaggle.com/datasets/abhi8923shriv/sentiment-analysis-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>night</td>\n",
       "      <td>70-100</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>97929</td>\n",
       "      <td>440.0</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e0c6d75b1</td>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>45195774</td>\n",
       "      <td>2736690.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50e14c0bb8</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>2963243</td>\n",
       "      <td>28470.0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e050245fbd</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Australia</td>\n",
       "      <td>25499884</td>\n",
       "      <td>7682300.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc2cbefa9d</td>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>Wow... u just became cooler.</td>\n",
       "      <td>positive</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Austria</td>\n",
       "      <td>9006398</td>\n",
       "      <td>82400.0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "5  28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
       "6  6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n",
       "7  50e14c0bb8                                         Soooo high   \n",
       "8  e050245fbd                                        Both of you   \n",
       "9  fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n",
       "\n",
       "                                       selected_text sentiment Time of Tweet  \\\n",
       "0                I`d have responded, if I were going   neutral       morning   \n",
       "1                                           Sooo SAD  negative          noon   \n",
       "2                                        bullying me  negative         night   \n",
       "3                                     leave me alone  negative       morning   \n",
       "4                                      Sons of ****,  negative          noon   \n",
       "5  http://www.dothebouncy.com/smf - some shameles...   neutral         night   \n",
       "6                                                fun  positive       morning   \n",
       "7                                         Soooo high   neutral          noon   \n",
       "8                                        Both of you   neutral         night   \n",
       "9                       Wow... u just became cooler.  positive       morning   \n",
       "\n",
       "  Age of User              Country  Population -2020  Land Area (Km²)  \\\n",
       "0        0-20          Afghanistan          38928346         652860.0   \n",
       "1       21-30              Albania           2877797          27400.0   \n",
       "2       31-45              Algeria          43851044        2381740.0   \n",
       "3       46-60              Andorra             77265            470.0   \n",
       "4       60-70               Angola          32866272        1246700.0   \n",
       "5      70-100  Antigua and Barbuda             97929            440.0   \n",
       "6        0-20            Argentina          45195774        2736690.0   \n",
       "7       21-30              Armenia           2963243          28470.0   \n",
       "8       31-45            Australia          25499884        7682300.0   \n",
       "9       46-60              Austria           9006398          82400.0   \n",
       "\n",
       "   Density (P/Km²)  \n",
       "0               60  \n",
       "1              105  \n",
       "2               18  \n",
       "3              164  \n",
       "4               26  \n",
       "5              223  \n",
       "6               17  \n",
       "7              104  \n",
       "8                3  \n",
       "9              109  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(filename_data, sep=',', encoding='unicode_escape')\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cantidad de filas: 27480\n",
      "Cantidad de columnas: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "Cantidad de filas: {df.shape[0]}\n",
    "Cantidad de columnas: {df.shape[1]}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPPreprocessor:\n",
    "\n",
    "    tokenizer_pattern = (\n",
    "            r'[\\U0001F600-\\U0001F64F]'          # classic emojis\n",
    "            r'|[\\U0001F300-\\U0001F5FF]'         # nature, symbols\n",
    "            r'|[\\U0001F680-\\U0001F6FF]'         # transport\n",
    "            r'|[\\U0001F1E0-\\U0001F1FF]'         # Flags\n",
    "            r'|[\\U00002700-\\U000027BF]'         # various symbols\n",
    "            r'|[\\U0001F900-\\U0001F9FF]'         # gestures\n",
    "            r'|[\\U00002600-\\U000026FF]'         # ☀☂\n",
    "            r'|❤|🥰'                            # specific emojis\n",
    "            r'|:\\)'                             # emoticon :)\n",
    "            r'|\\b\\w+\\b'                         # words (alphanumeric)\n",
    "        )\n",
    "\n",
    "    def __init__(self, text_column: str):\n",
    "        self.text_column = text_column\n",
    "\n",
    "    def clean_tokenize_text(self, text: str) -> list:\n",
    "        \"\"\" Tokenizes text and removes emojis, emoticons, and special characters.\"\"\"\n",
    "\n",
    "        tokenizer = RegexpTokenizer(self.tokenizer_pattern)\n",
    "        return tokenizer.tokenize(text.lower())\n",
    "\n",
    "    def _get_wordnet_pos_(self, treebank_tag) -> str:\n",
    "        \"\"\"\n",
    "        Converts nltk (Treebank) POS tags to WordNet tags.\n",
    "        \"\"\"\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN  # By default, use NOUN if no match found\n",
    "\n",
    "\n",
    "    def lemmatize_tokens(self, tokens: list) -> list:\n",
    "        \"\"\"Lemmatize tokens using POS tagging for greater accuracy.\"\"\"\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        pos_tags = pos_tag(tokens)  # [('los', 'DT'), ('niños', 'NNS'), ...]\n",
    "        return [\n",
    "            lemmatizer.lemmatize(token, self._get_wordnet_pos_(pos))\n",
    "            for token, pos in pos_tags\n",
    "        ]\n",
    "\n",
    "    def stem_tokens(self, tokens: list) -> list:\n",
    "        \"\"\"Stem tokens using PorterStemmer.\"\"\"\n",
    "        stemmer = PorterStemmer().stem\n",
    "        return [stemmer(token) for token in tokens]\n",
    "\n",
    "    def preprocess(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df['tokens'] = df[self.text_column].astype(str).apply(self.clean_tokenize_text)\n",
    "        df['lemmas'] = df['tokens'].apply(self.lemmatize_tokens)\n",
    "        df['stems'] = df['tokens'].apply(self.stem_tokens)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "      <td>[i, d, have, responded, if, i, were, going]</td>\n",
       "      <td>[i, d, have, respond, if, i, be, go]</td>\n",
       "      <td>[i, d, have, respond, if, i, were, go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "      <td>[my, boss, is, bullying, me]</td>\n",
       "      <td>[my, bos, be, bully, me]</td>\n",
       "      <td>[my, boss, is, bulli, me]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "      <td>[what, interview, leav, me, alon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "      <td>[sons, of, why, couldn, t, they, put, them, on...</td>\n",
       "      <td>[son, of, why, couldn, t, they, put, them, on,...</td>\n",
       "      <td>[son, of, whi, couldn, t, they, put, them, on,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>night</td>\n",
       "      <td>70-100</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>97929</td>\n",
       "      <td>440.0</td>\n",
       "      <td>223</td>\n",
       "      <td>[http, www, dothebouncy, com, smf, some, shame...</td>\n",
       "      <td>[http, www, dothebouncy, com, smf, some, shame...</td>\n",
       "      <td>[http, www, dothebounci, com, smf, some, shame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e0c6d75b1</td>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>45195774</td>\n",
       "      <td>2736690.0</td>\n",
       "      <td>17</td>\n",
       "      <td>[2am, feedings, for, the, baby, are, fun, when...</td>\n",
       "      <td>[2am, feeding, for, the, baby, be, fun, when, ...</td>\n",
       "      <td>[2am, feed, for, the, babi, are, fun, when, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50e14c0bb8</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>2963243</td>\n",
       "      <td>28470.0</td>\n",
       "      <td>104</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>[soooo, high]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e050245fbd</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Australia</td>\n",
       "      <td>25499884</td>\n",
       "      <td>7682300.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[both, of, you]</td>\n",
       "      <td>[both, of, you]</td>\n",
       "      <td>[both, of, you]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc2cbefa9d</td>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>Wow... u just became cooler.</td>\n",
       "      <td>positive</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Austria</td>\n",
       "      <td>9006398</td>\n",
       "      <td>82400.0</td>\n",
       "      <td>109</td>\n",
       "      <td>[journey, wow, u, just, became, cooler, hehe, ...</td>\n",
       "      <td>[journey, wow, u, just, become, cool, hehe, be...</td>\n",
       "      <td>[journey, wow, u, just, becam, cooler, hehe, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "5  28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
       "6  6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n",
       "7  50e14c0bb8                                         Soooo high   \n",
       "8  e050245fbd                                        Both of you   \n",
       "9  fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n",
       "\n",
       "                                       selected_text sentiment Time of Tweet  \\\n",
       "0                I`d have responded, if I were going   neutral       morning   \n",
       "1                                           Sooo SAD  negative          noon   \n",
       "2                                        bullying me  negative         night   \n",
       "3                                     leave me alone  negative       morning   \n",
       "4                                      Sons of ****,  negative          noon   \n",
       "5  http://www.dothebouncy.com/smf - some shameles...   neutral         night   \n",
       "6                                                fun  positive       morning   \n",
       "7                                         Soooo high   neutral          noon   \n",
       "8                                        Both of you   neutral         night   \n",
       "9                       Wow... u just became cooler.  positive       morning   \n",
       "\n",
       "  Age of User              Country  Population -2020  Land Area (Km²)  \\\n",
       "0        0-20          Afghanistan          38928346         652860.0   \n",
       "1       21-30              Albania           2877797          27400.0   \n",
       "2       31-45              Algeria          43851044        2381740.0   \n",
       "3       46-60              Andorra             77265            470.0   \n",
       "4       60-70               Angola          32866272        1246700.0   \n",
       "5      70-100  Antigua and Barbuda             97929            440.0   \n",
       "6        0-20            Argentina          45195774        2736690.0   \n",
       "7       21-30              Armenia           2963243          28470.0   \n",
       "8       31-45            Australia          25499884        7682300.0   \n",
       "9       46-60              Austria           9006398          82400.0   \n",
       "\n",
       "   Density (P/Km²)                                             tokens  \\\n",
       "0               60        [i, d, have, responded, if, i, were, going]   \n",
       "1              105  [sooo, sad, i, will, miss, you, here, in, san,...   \n",
       "2               18                       [my, boss, is, bullying, me]   \n",
       "3              164                [what, interview, leave, me, alone]   \n",
       "4               26  [sons, of, why, couldn, t, they, put, them, on...   \n",
       "5              223  [http, www, dothebouncy, com, smf, some, shame...   \n",
       "6               17  [2am, feedings, for, the, baby, are, fun, when...   \n",
       "7              104                                      [soooo, high]   \n",
       "8                3                                    [both, of, you]   \n",
       "9              109  [journey, wow, u, just, became, cooler, hehe, ...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0               [i, d, have, respond, if, i, be, go]   \n",
       "1  [sooo, sad, i, will, miss, you, here, in, san,...   \n",
       "2                           [my, bos, be, bully, me]   \n",
       "3                [what, interview, leave, me, alone]   \n",
       "4  [son, of, why, couldn, t, they, put, them, on,...   \n",
       "5  [http, www, dothebouncy, com, smf, some, shame...   \n",
       "6  [2am, feeding, for, the, baby, be, fun, when, ...   \n",
       "7                                      [soooo, high]   \n",
       "8                                    [both, of, you]   \n",
       "9  [journey, wow, u, just, become, cool, hehe, be...   \n",
       "\n",
       "                                               stems  \n",
       "0             [i, d, have, respond, if, i, were, go]  \n",
       "1  [sooo, sad, i, will, miss, you, here, in, san,...  \n",
       "2                          [my, boss, is, bulli, me]  \n",
       "3                  [what, interview, leav, me, alon]  \n",
       "4  [son, of, whi, couldn, t, they, put, them, on,...  \n",
       "5  [http, www, dothebounci, com, smf, some, shame...  \n",
       "6  [2am, feed, for, the, babi, are, fun, when, he...  \n",
       "7                                      [soooo, high]  \n",
       "8                                    [both, of, you]  \n",
       "9  [journey, wow, u, just, becam, cooler, hehe, i...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "preprocessor = NLPPreprocessor(text_column='text')\n",
    "processed_df = preprocessor.preprocess(df)\n",
    "processed_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de filas en train: 21984\n",
      "Cantidad de columnas en train: 13\n",
      "Cantidad de filas en test: 5496\n",
      "Cantidad de columnas en test: 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_df, test_df = train_test_split(processed_df, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = train_df['text']\n",
    "x_test = test_df['text']\n",
    "y_train = train_df['sentiment']\n",
    "y_test = test_df['sentiment']\n",
    "\n",
    "print(f'''Cantidad de filas en train: {train_df.shape[0]}\n",
    "Cantidad de columnas en train: {train_df.shape[1]}\n",
    "Cantidad de filas en test: {test_df.shape[0]}\n",
    "Cantidad de columnas en test: {test_df.shape[1]}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_x_train shape: (21984, 38762)\n",
      "tfidf_x_test shape: (5496, 38762)\n"
     ]
    }
   ],
   "source": [
    "# Model creation using TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(token_pattern=r'[^\\s]+')\n",
    "\n",
    "# Vectorize the text data\n",
    "tfidf_x_train = tfidf_vectorizer.fit_transform(x_train)\n",
    "tfidf_x_test = tfidf_vectorizer.transform(x_test)\n",
    "\n",
    "print(f'''tfidf_x_train shape: {tfidf_x_train.shape}\\ntfidf_x_test shape: {tfidf_x_test.shape}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_x_train_df shape: (21984, 38762)\n",
      "tfidf_x_test_df shape: (5496, 38762)\n"
     ]
    }
   ],
   "source": [
    "# Get feature names from the TF-IDF vectorizer\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the TF-IDF matrix back to a DataFrame\n",
    "tfidf_x_train_df = pd.DataFrame(tfidf_x_train.toarray(), columns=feature_names)\n",
    "tfidf_x_test_df = pd.DataFrame(tfidf_x_test.toarray(), columns=feature_names)\n",
    "\n",
    "print(f'''tfidf_x_train_df shape: {tfidf_x_train_df.shape}\\ntfidf_x_test_df shape: {tfidf_x_test_df.shape}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>!!</th>\n",
       "      <th>!!!</th>\n",
       "      <th>!!!!</th>\n",
       "      <th>!!!!!</th>\n",
       "      <th>!!!!!!</th>\n",
       "      <th>!!!!!!!</th>\n",
       "      <th>!!!!!!!!</th>\n",
       "      <th>!!!!!!!!!</th>\n",
       "      <th>!!!!!!!!!!!!!!!!!!!!!!!</th>\n",
       "      <th>...</th>\n",
       "      <th>ã¯â¿â½greed,ã¯â¿â½</th>\n",
       "      <th>ã¯â¿â½iã¯â¿â½m</th>\n",
       "      <th>ã¯â¿â½n?eleg</th>\n",
       "      <th>ã¯â¿â½stupidityã¯â¿â½</th>\n",
       "      <th>ã¯â¿â½timo</th>\n",
       "      <th>ã¯â¿â½why?</th>\n",
       "      <th>ã¯â¿â½whyyy????????</th>\n",
       "      <th>ã¯â¿â½you</th>\n",
       "      <th>ã¯â¿â½ã¯â¿â½</th>\n",
       "      <th>ã¯â¿â½ã¯â¿â½h.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 38762 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     !   !!  !!!  !!!!  !!!!!  !!!!!!  !!!!!!!  !!!!!!!!  !!!!!!!!!  \\\n",
       "0  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "1  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "2  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "3  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "4  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "5  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "6  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "7  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "8  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "9  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "\n",
       "   !!!!!!!!!!!!!!!!!!!!!!!  ...  ã¯â¿â½greed,ã¯â¿â½  ã¯â¿â½iã¯â¿â½m  \\\n",
       "0                      0.0  ...                 0.0             0.0   \n",
       "1                      0.0  ...                 0.0             0.0   \n",
       "2                      0.0  ...                 0.0             0.0   \n",
       "3                      0.0  ...                 0.0             0.0   \n",
       "4                      0.0  ...                 0.0             0.0   \n",
       "5                      0.0  ...                 0.0             0.0   \n",
       "6                      0.0  ...                 0.0             0.0   \n",
       "7                      0.0  ...                 0.0             0.0   \n",
       "8                      0.0  ...                 0.0             0.0   \n",
       "9                      0.0  ...                 0.0             0.0   \n",
       "\n",
       "   ã¯â¿â½n?eleg  ã¯â¿â½stupidityã¯â¿â½  ã¯â¿â½timo  ã¯â¿â½why?  \\\n",
       "0           0.0                    0.0         0.0         0.0   \n",
       "1           0.0                    0.0         0.0         0.0   \n",
       "2           0.0                    0.0         0.0         0.0   \n",
       "3           0.0                    0.0         0.0         0.0   \n",
       "4           0.0                    0.0         0.0         0.0   \n",
       "5           0.0                    0.0         0.0         0.0   \n",
       "6           0.0                    0.0         0.0         0.0   \n",
       "7           0.0                    0.0         0.0         0.0   \n",
       "8           0.0                    0.0         0.0         0.0   \n",
       "9           0.0                    0.0         0.0         0.0   \n",
       "\n",
       "   ã¯â¿â½whyyy????????  ã¯â¿â½you  ã¯â¿â½ã¯â¿â½  ã¯â¿â½ã¯â¿â½h.  \n",
       "0                  0.0        0.0           0.0             0.0  \n",
       "1                  0.0        0.0           0.0             0.0  \n",
       "2                  0.0        0.0           0.0             0.0  \n",
       "3                  0.0        0.0           0.0             0.0  \n",
       "4                  0.0        0.0           0.0             0.0  \n",
       "5                  0.0        0.0           0.0             0.0  \n",
       "6                  0.0        0.0           0.0             0.0  \n",
       "7                  0.0        0.0           0.0             0.0  \n",
       "8                  0.0        0.0           0.0             0.0  \n",
       "9                  0.0        0.0           0.0             0.0  \n",
       "\n",
       "[10 rows x 38762 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 rows of the TF-IDF DataFrame\n",
    "tfidf_x_train_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>!!</th>\n",
       "      <th>!!!</th>\n",
       "      <th>!!!!</th>\n",
       "      <th>!!!!!</th>\n",
       "      <th>!!!!!!</th>\n",
       "      <th>!!!!!!!</th>\n",
       "      <th>!!!!!!!!</th>\n",
       "      <th>!!!!!!!!!</th>\n",
       "      <th>!!!!!!!!!!!!!!!!!!!!!!!</th>\n",
       "      <th>...</th>\n",
       "      <th>ã¯â¿â½greed,ã¯â¿â½</th>\n",
       "      <th>ã¯â¿â½iã¯â¿â½m</th>\n",
       "      <th>ã¯â¿â½n?eleg</th>\n",
       "      <th>ã¯â¿â½stupidityã¯â¿â½</th>\n",
       "      <th>ã¯â¿â½timo</th>\n",
       "      <th>ã¯â¿â½why?</th>\n",
       "      <th>ã¯â¿â½whyyy????????</th>\n",
       "      <th>ã¯â¿â½you</th>\n",
       "      <th>ã¯â¿â½ã¯â¿â½</th>\n",
       "      <th>ã¯â¿â½ã¯â¿â½h.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 38762 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     !   !!  !!!  !!!!  !!!!!  !!!!!!  !!!!!!!  !!!!!!!!  !!!!!!!!!  \\\n",
       "0  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "1  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "2  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "3  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "4  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "5  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "6  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "7  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "8  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "9  0.0  0.0  0.0   0.0    0.0     0.0      0.0       0.0        0.0   \n",
       "\n",
       "   !!!!!!!!!!!!!!!!!!!!!!!  ...  ã¯â¿â½greed,ã¯â¿â½  ã¯â¿â½iã¯â¿â½m  \\\n",
       "0                      0.0  ...                 0.0             0.0   \n",
       "1                      0.0  ...                 0.0             0.0   \n",
       "2                      0.0  ...                 0.0             0.0   \n",
       "3                      0.0  ...                 0.0             0.0   \n",
       "4                      0.0  ...                 0.0             0.0   \n",
       "5                      0.0  ...                 0.0             0.0   \n",
       "6                      0.0  ...                 0.0             0.0   \n",
       "7                      0.0  ...                 0.0             0.0   \n",
       "8                      0.0  ...                 0.0             0.0   \n",
       "9                      0.0  ...                 0.0             0.0   \n",
       "\n",
       "   ã¯â¿â½n?eleg  ã¯â¿â½stupidityã¯â¿â½  ã¯â¿â½timo  ã¯â¿â½why?  \\\n",
       "0           0.0                    0.0         0.0         0.0   \n",
       "1           0.0                    0.0         0.0         0.0   \n",
       "2           0.0                    0.0         0.0         0.0   \n",
       "3           0.0                    0.0         0.0         0.0   \n",
       "4           0.0                    0.0         0.0         0.0   \n",
       "5           0.0                    0.0         0.0         0.0   \n",
       "6           0.0                    0.0         0.0         0.0   \n",
       "7           0.0                    0.0         0.0         0.0   \n",
       "8           0.0                    0.0         0.0         0.0   \n",
       "9           0.0                    0.0         0.0         0.0   \n",
       "\n",
       "   ã¯â¿â½whyyy????????  ã¯â¿â½you  ã¯â¿â½ã¯â¿â½  ã¯â¿â½ã¯â¿â½h.  \n",
       "0                  0.0        0.0           0.0             0.0  \n",
       "1                  0.0        0.0           0.0             0.0  \n",
       "2                  0.0        0.0           0.0             0.0  \n",
       "3                  0.0        0.0           0.0             0.0  \n",
       "4                  0.0        0.0           0.0             0.0  \n",
       "5                  0.0        0.0           0.0             0.0  \n",
       "6                  0.0        0.0           0.0             0.0  \n",
       "7                  0.0        0.0           0.0             0.0  \n",
       "8                  0.0        0.0           0.0             0.0  \n",
       "9                  0.0        0.0           0.0             0.0  \n",
       "\n",
       "[10 rows x 38762 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 rows of the TF-IDF test DataFrame\n",
    "tfidf_x_test_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "Aplicamos el modelo para generar la representación vectorial, usando TfidfVectorizer e incluyendo el \n",
    "\n",
    "```\n",
    "token_pattern=r'[^\\s]+'\n",
    "```\n",
    "\n",
    "Por otra parte, realizamos el ajuste y transformación de los datos X de test, y por ultimo mostramos el DF resultante para cada caso.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_apis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
